{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spread-investigator",
   "metadata": {},
   "source": [
    "#### The highest score achieved so far is 88%\n",
    "#### below is a figure which will be provided in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [0.78, 0.73, 0.73, 0.75, 0.22, 0.73, 0.59, 0.57,0.45]\n",
    "\n",
    "plt.bar(['Adamic/Adar','Common','Jaccard','Cosine','Preferential','Katz1957','SimRank','Spectral Clustering','Modularity'], data,color=['b', 'r', 'yellow','b','g'])\n",
    "plt.title('Accuracy on Validation Set for 100 positive link prediction',fontsize=16,color='r')\n",
    "plt.xlabel('Algorithms Categories')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.rcParams['figure.figsize'] = (18.0, 3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-aside",
   "metadata": {},
   "source": [
    "# Data Preparation: Train, Test, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import package\n",
    "import networkx as nx\n",
    "from networkx.algorithms import tree\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import mat\n",
    "import numpy.linalg\n",
    "from numpy.linalg import eig as eigenValuesAndVectors\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy import linalg\n",
    "import sys\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "pos_File='val_positive.txt'\n",
    "neg_File='val_negative.txt'\n",
    "Val_G = nx.Graph()\n",
    "Val_pos_G = nx.Graph()\n",
    "Val_neg_G = nx.Graph()\n",
    "with open(pos_File) as file:\n",
    "    for line in file:\n",
    "        Node_L, Node_R = [str(x) for x in line.strip().split()]\n",
    "        Val_G.add_edge(Node_L,Node_R)\n",
    "        Val_pos_G.add_edge(Node_L,Node_R)\n",
    "with open(neg_File) as file:\n",
    "    for line in file:\n",
    "        Node_L, Node_R = [str(x) for x in line.strip().split()]\n",
    "        Val_G.add_edge(Node_L,Node_R)\n",
    "        Val_neg_G.add_edge(Node_L,Node_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "G = nx.Graph() #G = nx.DiGraph()\n",
    "Node_List = []\n",
    "FileName = \"training.txt\"\n",
    "with open(FileName) as file:\n",
    "    for line in file:\n",
    "        Node_L, Node_R = [str(x) for x in line.strip().split()]\n",
    "        Node_List.append(Node_L)\n",
    "        Node_List.append(Node_R)\n",
    "        G.add_edge(Node_L,Node_R)\n",
    "Node_List = list(set(Node_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nodes Dictionary-> G\n",
    "Nodes_Dictionary={}\n",
    "NN = list(G.nodes())\n",
    "for n in range(len(NN)):\n",
    "    Nodes_Dictionary[NN[n]] = n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-collective",
   "metadata": {},
   "source": [
    "## Neighbour_Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neighbour_Based(v_1,v_2,methods,Graph):\n",
    "    if methods == 'Adamic/Adar':\n",
    "        return tuple(nx.adamic_adar_index(Graph,[(v_1,v_2)]))[0][-1]\n",
    "    v_1_neighbour = list(Graph.neighbors(v_1))\n",
    "    v_2_neighbour = list(Graph.neighbors(v_2))\n",
    "    common_neighbour = set(v_1_neighbour) & set(v_2_neighbour) #find common\n",
    "    if methods == 'Common':\n",
    "        return len(common_neighbour)\n",
    "    if methods == 'Jaccard':\n",
    "        all_neighbour = set(v_1_neighbour) | set(v_2_neighbour) #union all\n",
    "        return len(common_neighbour) / len(all_neighbour)\n",
    "    if methods == 'Cosine':\n",
    "        return len(common_neighbour)/math.sqrt(len(v_1_neighbour)*len(v_2_neighbour))\n",
    "    if methods == 'Preferential':\n",
    "        return len(v_1_neighbour)*len(v_2_neighbour)\n",
    "    return \"Wrong Input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "way = ['Adamic/Adar','Common','Jaccard','Cosine','Preferential']\n",
    "for w in way:\n",
    "    Edge_Score = {}\n",
    "    for edge in Val_G.edges():\n",
    "        v_1,v_2=edge\n",
    "        Edge_Score[edge] = Neighbour_Based(v_1,v_2,w,G)\n",
    "    Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "    count = 0\n",
    "    for p in Predict:\n",
    "        a,b = p\n",
    "        if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "            count=count+1\n",
    "    print('the accuracy of',w,' is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-planner",
   "metadata": {},
   "source": [
    "## Random Walk-based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-monday",
   "metadata": {},
   "source": [
    "### Katz1957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Katz1953(v_1,v_2,Graph,max_step=2):\n",
    "    A = [(math.exp(1)**i) for i in range(max_step,0,-1)]\n",
    "    beta = [a/sum(A) for a in A]\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(1,max_step+1):\n",
    "        for path in nx.all_simple_paths(Graph, source=v_1, target=v_2, cutoff=i):\n",
    "            score = score + beta[i-1]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score = {}\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    Edge_Score[edge] = Katz1953(v_1,v_2,G)\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of Katz1953 is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-restaurant",
   "metadata": {},
   "source": [
    "### SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(list_1,list_2):\n",
    "    list_3 = []\n",
    "    for l1 in list_1:\n",
    "        for l2 in list_2:\n",
    "            list_3.append((l1,l2))\n",
    "    return list_3\n",
    "\n",
    "def simrank(v_1, v_2, _simrank,Graph,C=2,step  = 0, max_iterations=3):\n",
    "    if (v_1, v_2) not in _simrank:\n",
    "        _simrank[(v_1, v_2)]=0\n",
    "        if v_1 == v_2:\n",
    "            return 1\n",
    "        if step  == max_iterations:\n",
    "            return 0\n",
    "        in_neighbors_v1 = list(Graph.neighbors(v_1))\n",
    "        in_neighbors_v2 = list(Graph.neighbors(v_2))\n",
    "        L = len(in_neighbors_v1) * len(in_neighbors_v2)\n",
    "        if L == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            scale = C / (len(in_neighbors_v1) * len(in_neighbors_v2))\n",
    "            return scale * sum(simrank(w, x,_simrank, Graph,C,step +1) for w,x in product(in_neighbors_v1,in_neighbors_v2))\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score = {}\n",
    "#count = 0\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    _simrank = {}\n",
    "    simrank_value = simrank(v_1,v_2,_simrank,G,C=0.1, max_iterations=2)\n",
    "    Edge_Score[edge] = simrank_value\n",
    "    #print(count,':',simrank_value)\n",
    "    #count = count + 1\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of SimRank is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-briefs",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-award",
   "metadata": {},
   "source": [
    "###### https://networkx.org/documentation/stable/auto_examples/advanced/plot_eigenvalues.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laplacian_Matrix = nx.laplacian_matrix(Val_G) #very sparse\n",
    "\n",
    "eigenValues, eigenVectors =linalg.eig(Laplacian_Matrix.A)\n",
    "eigenVectors = eigenVectors.T\n",
    "\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[idx]\n",
    "\n",
    "#idx find the index node  in the position of idx\n",
    "idx_Dictionary = {}\n",
    "for i in range(len(idx)):\n",
    "    idx_Dictionary[idx[i]]=i\n",
    "    \n",
    "    \n",
    "#Nodes Dictionary-> Val_G\n",
    "Nodes_Dictionary_ForClustering={}\n",
    "NN = list(Val_G.nodes())\n",
    "for n in range(len(NN)):\n",
    "    Nodes_Dictionary_ForClustering[NN[n]] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score = {}\n",
    "#count = 0\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    n_1=Nodes_Dictionary_ForClustering[v_1] #Find Index the i-th in G.nodes()\n",
    "    n_2=Nodes_Dictionary_ForClustering[v_2] #Find Index the i-th in G.nodes()\n",
    "    idx_1 = idx_Dictionary[n_1] # find the index in the idx\n",
    "    idx_2 = idx_Dictionary[n_2] # find the index in the idx\n",
    "    score = numpy.linalg.norm(eigenVectors[:,-50:][idx_1]-eigenVectors[:,-50:][idx_2],1)\n",
    "    Edge_Score[edge] = -1*score\n",
    "\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of Spectral Clustering is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-spirituality",
   "metadata": {},
   "source": [
    "### Modularity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "Modularity_Matrix = nx.modularity_matrix(Val_G) #very sparse\n",
    "\n",
    "eigenValues, eigenVectors =linalg.eig(Modularity_Matrix.A)\n",
    "eigenVectors = eigenVectors.T\n",
    "\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[idx]\n",
    "\n",
    "#idx find the index node  in the position of idx\n",
    "idx_Dictionary = {}\n",
    "for i in range(len(idx)):\n",
    "    idx_Dictionary[idx[i]]=i\n",
    "    \n",
    "    \n",
    "#Nodes Dictionary-> Val_G\n",
    "Nodes_Dictionary_ForClustering={}\n",
    "NN = list(Val_G.nodes())\n",
    "for n in range(len(NN)):\n",
    "    Nodes_Dictionary_ForClustering[NN[n]] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "part = 1100\n",
    "Edge_Score = {}\n",
    "#count = 0\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    n_1=Nodes_Dictionary_ForClustering[v_1] #Find Index the i-th in G.nodes()\n",
    "    n_2=Nodes_Dictionary_ForClustering[v_2] #Find Index the i-th in G.nodes()\n",
    "    idx_1 = idx_Dictionary[n_1] # find the index in the idx\n",
    "    idx_2 = idx_Dictionary[n_2] # find the index in the idx\n",
    "    score = numpy.linalg.norm(eigenVectors[:,:part][idx_1]-eigenVectors[:,:part][idx_2],3)\n",
    "    Edge_Score[edge] = score\n",
    "\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of Modularity matrix is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-editing",
   "metadata": {},
   "source": [
    "## Random Walk-based Approaches to Node Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-spine",
   "metadata": {},
   "source": [
    "### RandomWalk+Ward2Vec = DeepWalk\n",
    "### address: https://github.com/PingEnLu/Random-Walk\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "raw",
   "id": "crude-minnesota",
   "metadata": {},
   "source": [
    "#! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'..\\Random_Walk')\n",
    "from random_walks import RandomWalk\n",
    "random_walk = RandomWalk(G, walk_length=25, num_walks=40, workers=1,p=0.1,q=1)\n",
    "walklist = random_walk.walks\n",
    "model = gensim.models.Word2Vec(walklist,window=3,sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score = {}\n",
    "#count = 0\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    em_1 = model.wv[int(v_1)]\n",
    "    em_2 = model.wv[int(v_2)]\n",
    "    score = em_1.dot(em_2)/math.sqrt(em_1.dot(em_1)+em_2.dot(em_2))\n",
    "    Edge_Score[edge] = score\n",
    "\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of DeepWalk is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-battery",
   "metadata": {},
   "source": [
    "### Normal Node2Vec\n",
    "### adress: https://github.com/eliorc/node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'..\\node2vec')\n",
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(G, dimensions=100, walk_length=40, num_walks=40, workers=1,p=0.1,q=1)\n",
    "model = node2vec.fit(window=3,sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score = {}\n",
    "\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    em_1 = model.wv[v_1]\n",
    "    em_2 = model.wv[v_2]\n",
    "    score = em_1.dot(em_2)/math.sqrt(em_1.dot(em_1)+em_2.dot(em_2))\n",
    "    Edge_Score[edge] = score\n",
    "\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of Node2Vec is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-blocking",
   "metadata": {},
   "source": [
    "# Mixed Function\n",
    "## Spectral Clustering+Cosine Neighbour Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Modularity_Matrix = nx.modularity_matrix(Val_G) #very sparse\n",
    "\n",
    "eigenValues, eigenVectors =linalg.eig(Modularity_Matrix.A)\n",
    "eigenVectors = eigenVectors.T\n",
    "\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[idx]\n",
    "\n",
    "#idx find the index node  in the position of idx\n",
    "idx_Dictionary = {}\n",
    "for i in range(len(idx)):\n",
    "    idx_Dictionary[idx[i]]=i\n",
    "    \n",
    "    \n",
    "#Nodes Dictionary-> Val_G\n",
    "Nodes_Dictionary_ForClustering={}\n",
    "NN = list(Val_G.nodes())\n",
    "for n in range(len(NN)):\n",
    "    Nodes_Dictionary_ForClustering[NN[n]] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score_Cosine = {}\n",
    "Edge_Score_Clustering = {}\n",
    "Edge_Score = {}\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    Edge_Score_Cosine[edge] = Neighbour_Based(v_1,v_2,'Cosine',G)\n",
    "    n_1=Nodes_Dictionary_ForClustering[v_1] #Find Index the i-th in G.nodes()\n",
    "    n_2=Nodes_Dictionary_ForClustering[v_2] #Find Index the i-th in G.nodes()\n",
    "    idx_1 = idx_Dictionary[n_1] # find the index in the idx\n",
    "    idx_2 = idx_Dictionary[n_2] # find the index in the idx\n",
    "    score = numpy.linalg.norm(eigenVectors[:,-50:][idx_1]-eigenVectors[:,-50:][idx_2],1)\n",
    "    Edge_Score_Clustering[edge] = -1*score\n",
    "    Edge_Score[edge] = 0.9*Edge_Score_Clustering[edge] + 1.5*Edge_Score_Cosine[edge]\n",
    "    \n",
    "    \n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of (spectral clustering+Cosine Neighbour Score) is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-international",
   "metadata": {},
   "source": [
    "# Mixed Function\n",
    "## Spectral Clustering+Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(G, dimensions=50, walk_length=20, num_walks=20, workers=1,p=0.1,q=1)\n",
    "model = node2vec.fit(window=3,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laplacian_Matrix = nx.laplacian_matrix(Val_G) #very sparse\n",
    "\n",
    "eigenValues, eigenVectors =linalg.eig(Laplacian_Matrix.A)\n",
    "eigenVectors = eigenVectors.T\n",
    "\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[idx]\n",
    "\n",
    "#idx find the index node  in the position of idx\n",
    "idx_Dictionary = {}\n",
    "for i in range(len(idx)):\n",
    "    idx_Dictionary[idx[i]]=i\n",
    "    \n",
    "    \n",
    "#Nodes Dictionary-> Val_G\n",
    "Nodes_Dictionary_ForClustering={}\n",
    "NN = list(Val_G.nodes())\n",
    "for n in range(len(NN)):\n",
    "    Nodes_Dictionary_ForClustering[NN[n]] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score = {}\n",
    "Edge_Score_node2Vec = {}\n",
    "Edge_Score_Clustering = {}\n",
    "#count = 0\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    \n",
    "    \n",
    "    em_1 = model.wv[v_1]\n",
    "    em_2 = model.wv[v_2]\n",
    "    score = em_1.dot(em_2)/math.sqrt(em_1.dot(em_1)+em_2.dot(em_2))\n",
    "    Edge_Score_node2Vec[edge] = score\n",
    "    \n",
    "    \n",
    "    n_1=Nodes_Dictionary_ForClustering[v_1] #Find Index the i-th in G.nodes()\n",
    "    n_2=Nodes_Dictionary_ForClustering[v_2] #Find Index the i-th in G.nodes()\n",
    "    idx_1 = idx_Dictionary[n_1] # find the index in the idx\n",
    "    idx_2 = idx_Dictionary[n_2] # find the index in the idx\n",
    "    score = numpy.linalg.norm(eigenVectors[:,-50:][idx_1]-eigenVectors[:,-50:][idx_2],1)\n",
    "    Edge_Score_Clustering[edge] = -1*score\n",
    "    \n",
    "    \n",
    "    Edge_Score[edge] = 4*Edge_Score_node2Vec[edge] + 10*Edge_Score_Clustering[edge]\n",
    "\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of (Modularity clustering+Node2Vec) is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-condition",
   "metadata": {},
   "source": [
    "# Mixed Function\n",
    "## Modularity Clustering+Cosine Neighbour Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "Modularity_Matrix = nx.modularity_matrix(Val_G) #very sparse\n",
    "\n",
    "eigenValues, eigenVectors =linalg.eig(Modularity_Matrix.A)\n",
    "eigenVectors = eigenVectors.T\n",
    "\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[idx]\n",
    "\n",
    "#idx find the index node  in the position of idx\n",
    "idx_Dictionary = {}\n",
    "for i in range(len(idx)):\n",
    "    idx_Dictionary[idx[i]]=i\n",
    "    \n",
    "    \n",
    "#Nodes Dictionary-> Val_G\n",
    "Nodes_Dictionary_ForClustering={}\n",
    "NN = list(Val_G.nodes())\n",
    "for n in range(len(NN)):\n",
    "    Nodes_Dictionary_ForClustering[NN[n]] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-marshall",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part = 1100\n",
    "Edge_Score_Cosine = {}\n",
    "Edge_Score_ModularityClustering = {}\n",
    "Edge_Score = {}\n",
    "#count = 0\n",
    "for edge in Val_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    Edge_Score_Cosine[edge] = Neighbour_Based(v_1,v_2,'Cosine',G)\n",
    "    #Edge_Score_Cosine[edge] = Katz1953(v_1,v_2,G)\n",
    "    \n",
    "    n_1=Nodes_Dictionary_ForClustering[v_1] #Find Index the i-th in G.nodes()\n",
    "    n_2=Nodes_Dictionary_ForClustering[v_2] #Find Index the i-th in G.nodes()\n",
    "    idx_1 = idx_Dictionary[n_1] # find the index in the idx\n",
    "    idx_2 = idx_Dictionary[n_2] # find the index in the idx\n",
    "    score = numpy.linalg.norm(eigenVectors[:,:part][idx_1]-eigenVectors[:,:part][idx_2],3)\n",
    "    Edge_Score_ModularityClustering[edge] = score\n",
    "    Edge_Score[edge] = 20*Edge_Score_ModularityClustering[edge] + 2*Edge_Score_Cosine[edge]\n",
    "\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]\n",
    "count = 0\n",
    "for p in Predict:\n",
    "    a,b = p\n",
    "    if (a,b) in Val_pos_G.edges() or (b,a) in Val_pos_G.edges():\n",
    "        count=count+1\n",
    "print('the accuracy of (Modularity clustering + Cosine Neighbour Score) is:',count / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-brazil",
   "metadata": {},
   "source": [
    "## Prediction: Spectral Clustering+Cosine Neighbour Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Prediction\n",
    "# Loading Test\n",
    "\n",
    "Test_G = nx.Graph() #G = nx.DiGraph()\n",
    "Node_List = []\n",
    "FileName = \"test.txt\"\n",
    "with open(FileName) as file:\n",
    "    for line in file:\n",
    "        Node_L, Node_R = [str(x) for x in line.strip().split()]\n",
    "        Node_List.append(Node_L)\n",
    "        Node_List.append(Node_R)\n",
    "        Test_G.add_edge(Node_L,Node_R)\n",
    "Node_List = list(set(Node_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(G, dimensions=50, walk_length=20, num_walks=20, workers=1,p=0.1,q=1)\n",
    "model = node2vec.fit(window=3,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laplacian_Matrix = nx.laplacian_matrix(Test_G) #very sparse\n",
    "\n",
    "eigenValues, eigenVectors =linalg.eig(Laplacian_Matrix.A)\n",
    "eigenVectors = eigenVectors.T\n",
    "\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[idx]\n",
    "\n",
    "#idx find the index node  in the position of idx\n",
    "idx_Dictionary = {}\n",
    "for i in range(len(idx)):\n",
    "    idx_Dictionary[idx[i]]=i\n",
    "    \n",
    "    \n",
    "#Nodes Dictionary-> Val_G\n",
    "Nodes_Dictionary_ForClustering={}\n",
    "NN = list(Test_G.nodes())\n",
    "for n in range(len(NN)):\n",
    "    Nodes_Dictionary_ForClustering[NN[n]] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Score = {}\n",
    "Edge_Score_node2Vec = {}\n",
    "Edge_Score_Clustering = {}\n",
    "#count = 0\n",
    "for edge in Test_G.edges():\n",
    "    v_1,v_2=edge\n",
    "    \n",
    "    \n",
    "    em_1 = model.wv[v_1]\n",
    "    em_2 = model.wv[v_2]\n",
    "    score = em_1.dot(em_2)/math.sqrt(em_1.dot(em_1)+em_2.dot(em_2))\n",
    "    Edge_Score_node2Vec[edge] = score\n",
    "    \n",
    "    \n",
    "    n_1=Nodes_Dictionary_ForClustering[v_1] #Find Index the i-th in G.nodes()\n",
    "    n_2=Nodes_Dictionary_ForClustering[v_2] #Find Index the i-th in G.nodes()\n",
    "    idx_1 = idx_Dictionary[n_1] # find the index in the idx\n",
    "    idx_2 = idx_Dictionary[n_2] # find the index in the idx\n",
    "    score = numpy.linalg.norm(eigenVectors[:,-50:][idx_1]-eigenVectors[:,-50:][idx_2],1)\n",
    "    Edge_Score_Clustering[edge] = -1*score\n",
    "    \n",
    "    \n",
    "    Edge_Score[edge] = 4*Edge_Score_node2Vec[edge] + 10*Edge_Score_Clustering[edge]\n",
    "\n",
    "Predict = sorted(Edge_Score, key=lambda x: Edge_Score[x],reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [pair[0]+' '+pair[1]+'\\n' for pair in Predict]\n",
    "with open('results.txt','w') as f:\n",
    "    f.writelines(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
