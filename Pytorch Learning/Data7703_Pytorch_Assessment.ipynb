{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ongoing-mixture",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.502343204461186\n",
      "0.5032242518817698\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn import linear_model \n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, lr=0.1, niter=100, momentum=0, random_state=None, verbose=False):\n",
    "        '''\n",
    "        Train a multiclass logistic regression model on the given training set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: training examples, represented as an input array of shape (n_sample,\n",
    "           n_features).\n",
    "        y: labels of training examples, represented as an array of shape\n",
    "           (n_sample,) containing the classes for the input examples\n",
    "        lr: learning rate for gradient descent\n",
    "        niter: number of gradient descent updates\n",
    "        momentum: the momentum constant (see assignment task sheet for an explanation)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: fitted model\n",
    "        '''\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.class2int = dict((c, i) for i, c in enumerate(self.classes_))\n",
    "        y = np.array([self.class2int[c] for c in y])\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        n_classes = len(self.classes_)\n",
    "\n",
    "        self.intercept_ = np.zeros(n_classes)\n",
    "        self.coef_ = np.zeros((n_classes, n_features))\n",
    "\n",
    "        # Implement your gradient descent training code here; uncomment the code below to do \"random training\"\n",
    "        #self.intercept_ = np.random.randn(*self.intercept_.shape)\n",
    "        #self.coef_ = np.random.randn(*self.coef_.shape)\n",
    "        \n",
    "        '''\n",
    "        Numpy to Torch\n",
    "        '''\n",
    "        coef = torch.from_numpy(self.coef_)\n",
    "        coef.requires_grad = True\n",
    "        intercept = torch.from_numpy(self.intercept_)\n",
    "        intercept.requires_grad = True\n",
    "        \n",
    "        optimizer = optim.SGD([coef, intercept], lr=lr, momentum=momentum)\n",
    "        \n",
    "        X = torch.from_numpy(X)\n",
    "        \n",
    "        '''\n",
    "        Training Process\n",
    "        @ = torch.mm()\n",
    "        torch.mm()、torch.matmul()、@\n",
    "        '''\n",
    "        for i in range(niter):\n",
    "            scores = X @ coef.T + intercept\n",
    "            scores = scores - torch.max(scores, dim=1)[0].reshape(-1, 1)\n",
    "            scores = torch.exp(scores)\n",
    "            probs = scores/scores.sum(dim=1).reshape(-1, 1)\n",
    "            ll = -torch.log(probs[np.arange(0, len(y)), y]).mean()\n",
    "            \n",
    "            if verbose:\n",
    "                print('[%4d]: %.3f' % (i, ll.data))\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            ll.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        self.coef_ = coef.detach().numpy()\n",
    "        self.intercept_ = intercept.detach().numpy()\n",
    "\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Predict the class distributions for given input examples.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: input examples, represented as an input array of shape (n_sample,\n",
    "           n_features).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y: predicted class lables, represened as an array of shape (n_sample,\n",
    "           n_classes)\n",
    "        '''\n",
    "\n",
    "        # replace pass with your code\n",
    "        scores = X @ self.coef_.T + self.intercept_\n",
    "        scores = scores - np.max(scores, axis=1).reshape(-1, 1)\n",
    "        scores = np.exp(scores)\n",
    "        return scores/scores.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict the classes for given input examples.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: input examples, represented as an input array of shape (n_sample,\n",
    "           n_features).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y: predicted class lables, represened as an array of shape (n_sample,)\n",
    "        '''\n",
    "\n",
    "        # replace pass with your code\n",
    "        scores = X @ self.coef_.T + self.intercept_\n",
    "        indices = np.argmax(scores, axis=1)\n",
    "        return self.classes_[indices]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, y = fetch_covtype(return_X_y=True)\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_tr, y_tr, lr=2e-7, niter=200);\n",
    "    print(accuracy_score(y_tr, clf.predict(X_tr)))\n",
    "    print(accuracy_score(y_ts, clf.predict(X_ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-capability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
